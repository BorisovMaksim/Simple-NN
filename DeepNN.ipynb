{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "70636609-0c99-4d99-8e9a-59eb3872bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fac5a2b5-6abd-495e-9159-b7361ee91b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cab9c74a-53ce-4a22-bd3f-e12759209070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2     3     4     5    6    7    8    9   ...   54   55  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  4.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  2.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  8.0  0.0   \n",
       "\n",
       "       56   57   58    59    60    61   62   63  \n",
       "0     0.0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3     0.0  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "...   ...  ...  ...   ...   ...   ...  ...  ...  \n",
       "1792  0.0  0.0  2.0  14.0  15.0   9.0  0.0  0.0  \n",
       "1793  0.0  0.0  6.0  16.0  14.0   6.0  0.0  0.0  \n",
       "1794  0.0  0.0  2.0   9.0  13.0   6.0  0.0  0.0  \n",
       "1795  0.0  0.0  5.0  12.0  16.0  12.0  0.0  0.0  \n",
       "1796  0.0  1.0  8.0  12.0  14.0  12.0  1.0  0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(digits.data)\n",
    "target = digits['target'].reshape(-1,1)\n",
    "target = (target == 5) + 0\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "065737ed-e439-4036-85f1-5bd47d91db5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a3a24a9b-771e-4f3a-ab65-6c86cbad1346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 30\n",
    "images = digits.images\n",
    "example_image = images[num]\n",
    "plt.imshow(example_image, cmap=plt.get_cmap('gray'))\n",
    "plt.title(f\"digit is 5 = {target[num]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a0831fbc-61be-44cd-a8bb-a7270c55b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.15, random_state=42)\n",
    "X_train = X_train.values.reshape(64,-1)\n",
    "X_test = X_test.values.reshape(64,-1)\n",
    "y_train = y_train.reshape(1, -1)\n",
    "y_test = y_test.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d1bd8dbb-4fdd-40cc-a36e-e42d6fd799d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1527)\n",
      "(1, 1527)\n",
      "(64, 270)\n",
      "(1, 270)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436708a8-63c0-4e29-8f7b-dbf032e391ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  What is my architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57174b3d-a5fb-46a3-a25f-da05553559ba",
   "metadata": {},
   "source": [
    "|   Input Layer |  First Hidden Layer   | Second Hidden Layer   |  Output Layer  |  \n",
    "|---|:---:|---|---|\n",
    "| $$A^{[0]} = X$$                   | $$Z^{[1]} = W^{[1] } A^{[0]} + b^{[1]}$$   |  $$Z^{[2]} = W^{[2] } A^{[1]} + b^{[2]}$$   |    $$Z^{[3]} = W^{[3] } A^{[2]} + b^{[3]}$$     |\n",
    "|                                   | $$A^{[1]} = ReLU(Z^{[1]})$$                 |  $$A^{[2]} = ReLU(Z^{[2]})$$                 |    $$A^{[3]} = Sigmoid(Z^{[3]})$$                |\n",
    "| | | | \n",
    "| | | | \n",
    "| | | | \n",
    "| | | | \n",
    "|                                   | $$W^{[1]}.shape = (n_{h}^{[1]}, n_x) $$               |  $$W^{[2]}.shape = (n_{h}^{[2]}, n_{h}^{[1]}) $$               |   $$W^{[3]}.shape = (n_{y}, n_{h}^{[2]}) $$                  |\n",
    "| $$A^{[0]}.shape = (n_x, num\\_examples) $$   | $$ Z^{[1]}.shape = (n_{h}^{[1]}, num\\_examples) $$            |  $$ Z^{[2]}.shape = (n_{h}^{[2]}, num\\_examples) $$            |      $$ Z^{[3]}.shape = (n_{y}, num\\_examples) $$            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d565759-9195-4e53-9ff5-a86757865fe6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Теоретический материал"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad3286-b583-4ca8-8863-64299bde3b41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Определение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7023a55-7f29-455c-94b7-4e731a84ff75",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"font-family:Papyrus; font-size:2em;\">\n",
    "    Функция $ f:\\mathbb{R}^m\\rightarrow\\mathbb{R}^n$ дифференцируема в точке $x_0$, если \n",
    "    $$f(x_0 + h) = f(x_0) + \\color{#348FEA}{\\left[D_{x_0} f \\right]} (h) + \\bar{\\bar{o}} \\left(\\left| \\left| h\\right|\\right|\\right), $$\n",
    "    где $\\color{#348FEA}{\\big[D_{x_0} f\\big]}$ - дифференциал функции $f$\n",
    "    \n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7338ca-9f37-4abe-82d1-8b4fd2aa67c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Градиент сложной функции\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f5b21-6533-4f71-9f4b-c107adbe0f7c",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:2em;\">\n",
    "Формула производной сложной функции\n",
    "$$\\left[D_{x_0} (\\color{#5002A7}{u} \\circ \\color{#4CB9C0}{v}) \\right](h) = \\color{#5002A7}{\\left[D_{v(x_0)} u \\right]} \\left( \\color{#4CB9C0}{\\left[D_{x_0} v\\right]} (h)\\right)$$\n",
    "Пусть $f(x) = g(h(x))$, тогда\n",
    "    \n",
    "$$\\left[D_{x_0} f \\right] (x-x_0) = \\langle\\nabla_{x_0} f, x-x_0\\rangle.$$\n",
    "    \n",
    "С другой стороны,\n",
    "\n",
    "$$\\left[D_{h(x_0)} g \\right] \\left(\\left[D_{x_0}h \\right] (x-x_0)\\right) = \\langle\\nabla_{h_{x_0}} g, \\left[D_{x_0} h\\right] (x-x_0)\\rangle = \\langle\\left[D_{x_0} h\\right]^* \\nabla_{h(x_0)} g, x-x_0\\rangle.$$\n",
    "    \n",
    "То есть $\\color{#FFC100}{\\nabla_{x_0} f} = \\color{#348FEA}{\\left[D_{x_0} h \\right]}^* \\color{#FFC100}{\\nabla_{h(x_0)}}g$ - применение сопряженного к $D_{x_0} h$ линейного отображения к вектору $\\nabla_{h(x_0)} g$\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747eb04a-e59d-48c6-ab89-b56aeaadba60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Градиенты для типичных слоёв"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becbb98d-81e0-4e48-83d2-11e39d83edd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### $f(x)=u(v(x))$ , где $x$ — вектор, а $v(x)$ – поэлементное применение $v$ $ \\;\\; \\Rightarrow \\;\\; \\color{#348FEA}{\\nabla_{x_0} f  = v'(x_0) \\odot \\left[\\nabla_{v(x_0)} u\\right]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353feb6-f06e-49fb-97ad-c68affa184f4",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:2em;\">\n",
    "\n",
    "$$v\\begin{pmatrix}\n",
    " x_1 \\\\\n",
    " \\vdots\\\\\n",
    " x_N\n",
    " \\end{pmatrix}\n",
    " = \\begin{pmatrix}\n",
    " v(x_1)\\\\\n",
    " \\vdots\\\\\n",
    " v(x_N)\n",
    " \\end{pmatrix}$$\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa80372a-c99b-44f0-9fde-20e7293aa6f2",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:2em;\">\n",
    "Тогда, как мы знаем,\n",
    "    $$\\left[D_{x_0} f\\right] (h) = \\langle\\nabla_{x_0} f, h\\rangle = \\left[\\nabla_{x_0} f\\right]^T h.$$\n",
    "    Следовательно,\n",
    "\n",
    "$$\\begin{multline*}\n",
    " \\left[D_{v(x_0)} u\\right] \\left( \\left[ D_{x_0} v\\right] (h)\\right) = \\left[\\nabla_{v(x_0)} u\\right]^T \\left(v'(x_0) \\odot h\\right)\n",
    " = \\sum\\limits_i \\left[\\nabla_{v(x_0)} u\\right]_i v'(x_{0i})h_i \n",
    " = \\langle\\left[\\nabla_{v(x_0)} u\\right] \\odot v'(x_0), h\\rangle.\n",
    " \\end{multline*},$$\n",
    "где ⊙ означает поэлементное перемножение. Окончательно получаем\n",
    "  $$\\color{#348FEA}{\\nabla_{x_0} f = \\left[\\nabla_{v(x_0)}u\\right] \\odot v'(x_0) = v'(x_0) \\odot \\left[\\nabla_{v(x_0)} u\\right]}$$\n",
    "\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f90f6e-8127-45c0-a388-764aaa8c6d5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### $f(X) = g(XW)$, где $X$ и $W$ - матрицы  $ \\;\\; \\Rightarrow \\;\\; \\color{#348FEA}{\\nabla_{X_0} f = \\left[\\nabla_{X_0W} (g) \\right] \\cdot W^T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e5d213-5ac5-42a6-8aa4-8344a04fd8f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"font-family:Papyrus; font-size:2em;\">\n",
    "\n",
    "Как мы знаем, \n",
    "    $$\\left[D_{X_0} f \\right] (X-X_0) = \\text{tr}\\, \\left(\\left[\\nabla_{X_0} f\\right]^T (X-X_0)\\right)$$\n",
    "Тогда\n",
    "    $$\\begin{multline*}\n",
    " \\left[ D_{X_0W} g \\right]  \\left(\\left[D_{X_0} \\left( \\ast W\\right)\\right] (H)\\right) = \n",
    " \\left[ D_{X_0W} g \\right]  \\left(HW\\right)=\\\\\n",
    "  = \\text{tr}\\, \\left( \\left[\\nabla_{X_0W} g \\right]^T \\cdot (H) W \\right) =\\\\\n",
    " =\n",
    "  \\text{tr} \\, \\left(W \\left[\\nabla_{X_0W} (g) \\right]^T \\cdot (H)\\right) = \\text{tr} \\, \\left( \\left[\\left[\\nabla_{X_0W} g\\right] W^T\\right]^T (H)\\right)\n",
    " \\end{multline*}$$\n",
    "\n",
    "Здесь через $\\ast W$ обозначено отображение $Y \\hookrightarrow  YW$, а в предпоследнем переходе использовалось следующее свойство следа:\n",
    "    $$\\text{tr} \\, (A B C) = \\text{tr} \\, (C A B),$$\n",
    "где $A,B,C$ — произвольные матрицы подходящих размеров (то есть допускающие перемножение в обоих приведённых порядках). Следовательно, получаем\n",
    "    $$\\color{#348FEA}{\\nabla_{X_0} f = \\left[\\nabla_{X_0W} (g) \\right] \\cdot W^T}$$\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c8e990-d6cc-46d9-b3d5-fdcd056b3e6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### $f(W) = g(XW)$, где $W$ и $X$ — матрицы $ \\;\\; \\Rightarrow \\;\\; \\color{#348FEA}{\\nabla_{X_0} f = X^T \\cdot \\left[\\nabla_{XW_0} (g)\\right]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea2007-47c3-499e-a4c8-330ced076f72",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:2em;\">\n",
    " Для приращения $H=W−W_0$ имеем\n",
    "    $$\\left[D_{W_0} f \\right] (H) = \\text{tr} \\, \\left( \\left[\\nabla_{W_0} f \\right]^T (H)\\right)$$\n",
    "    Тогда\n",
    "    $$\\begin{multline*}\n",
    " \\left[D_{XW_0} g \\right] \\left( \\left[D_{W_0} \\left(X \\ast\\right) \\right] (H)\\right) = \\left[D_{XW_0} g \\right] \\left( XH \\right) = \\\\\n",
    " = \\text{tr} \\, \\left( \\left[\\nabla_{XW_0} g \\right]^T \\cdot X (H)\\right) =\n",
    "  \\text{tr}\\, \\left(\\left[X^T \\left[\\nabla_{XW_0} g \\right] \\right]^T (H)\\right)\n",
    " \\end{multline*}$$\n",
    "\n",
    "Здесь через $X \\ast$ обозначено отображение $Y \\hookrightarrow XY$. Значит,\n",
    "    $$\\color{#348FEA}{\\nabla_{X_0} f = X^T \\cdot \\left[\\nabla_{XW_0} (g)\\right]}$$\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f0133-1cda-4a27-88ea-c033022676b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe57bf-bd89-4dce-8e5d-be67d1ef7db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "512c8b7a-1b27-49c2-9b91-c300fd5a6250",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How to do backward propagation in this case?\n",
    "$\\huge \\frac{\\partial \\mathcal{L}}{\\partial W^{[1]}}, \\frac{\\partial \\mathcal{L}}{\\partial b^{[1]}}, \\frac{\\partial \\mathcal{L}}{\\partial W^{[2]}} , \\frac{\\partial \\mathcal{L}}{\\partial b^{[2]}}, \\frac{\\partial \\mathcal{L}}{\\partial W^{[3]}}, \\frac{\\partial \\mathcal{L}}{\\partial b^{[3]}}?$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d35cea-d5f6-4e75-912d-136ef37f5c86",
   "metadata": {},
   "source": [
    "$$ \\Large  \\mathcal{L}(A^{[3]}, Y) = -\\frac{1}{m} \\sum_{i=1}^{m}y_i log(A^{[3]}_i) + (1 - y_i) log(1 - A^{[3]}_i) = -\\frac{1}{m}( Y^T log(A^{[3]}) + (1 - Y)^T log(1 - A^{[3]})) $$\n",
    "\n",
    "$$ \\Large  A^{[3]}= Sigmoid(Z^{[3]})$$\n",
    "\n",
    " $$ \\Large  Z^{[3]} = W^{[3] } A^{[2]} + b^{[3]}$$ \n",
    "  $$ \\Large  A^{[2]} = ReLU(Z^{[2]})$$    \n",
    "   $$ \\Large  Z^{[2]} = W^{[2] } A^{[1]} + b^{[2]}$$   \n",
    "   $$  \\Large A^{[1]} = ReLU(Z^{[1]})$$ \n",
    "   $$  \\Large  Z^{[1]} = W^{[1] } A^{[0]} + b^{[1]}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d65ec0-b048-4e4a-b576-c140f1dbe243",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $\\large \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial W^{[3]}}}_{n_{y} \\times n_{h}^{[2]}} = \\frac{1}{m} \\underbrace{\\left(A^{[3]}_{0} - Y \\right)}_{n_{y} \\times m} \\underbrace{A^{[2]T}_{0}}_{m \\times n_{h}^{[2]}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232fecd-5046-4da4-95cd-597c11684849",
   "metadata": {},
   "source": [
    "$\\Large \\nabla_{W^{[3]}_{0}} \\mathcal{L}=  \\nabla_{W^{[3]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[W^{[3]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right] \\right) $\n",
    "\n",
    "$\\Large = \\nabla_{W^{[3]}_{0}A^{[2]} + b^{[3]} } \\left( \\mathcal{L} \\circ \\sigma \\right) A^{[2]T}_{0}  = $\n",
    "\n",
    "$\\Large  = \\nabla_{ Z^{[3]}_{0} } \\left( \\mathcal{L} \\circ \\sigma \\right) A^{[2]T}_{0}  = \\sigma'(Z^{[3]}_{0}) \\odot \\left[  \\nabla_{ A^{[3]}_{0} }  \\mathcal{L}  \\right] A^{[2]T}_{0} = $\n",
    "\n",
    "$\\Large = A^{[3]}_{0} \\odot (1 - A^{[3]}_{0}) \\odot \\left[ \\left(\\frac{1}{ A^{[3]}_{0}} \\odot -\\frac{1}{m}Y \\right) + \\left(\\frac{1}{1 - A^{[3]}_{0}} \\odot \\frac{1}{m}(1 - Y) \\right)    \\right] A^{[2]T}_{0}  $ \n",
    "\n",
    "$\\Large  = \\left[ \\left(1 - A^{[3]}_{0} \\odot -\\frac{1}{m}Y \\right) + \\left(A^{[3]}_{0} \\odot \\frac{1}{m}(1 - Y) \\right)    \\right] A^{[2]T}$\n",
    "\n",
    "$= \\Large \\frac{1}{m} \\left(A^{[3]}_{0} - Y \\right)A^{[2]T}_{0}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb8584-92fc-4d14-8a03-f85bd76a6224",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $\\large \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial b^{[3]}}}_{n_{y} \\times 1} = \\frac{1}{m} np.sum(\\underbrace{A^{[3]}_{0} - Y}_{n_{y} \\times m} , axis=1, keepdims=True)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c675f2-3124-4d30-a933-f3fa14ef1183",
   "metadata": {},
   "source": [
    "$\\Large \\nabla_{b^{[3]}_{0}} \\mathcal{L}=  \\nabla_{b^{[3]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[b^{[3]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right] \\right) $\n",
    "\n",
    "$\\Large = \\nabla_{W^{[3]}_{0}A^{[2]} + b^{[3]} } \\left( \\mathcal{L} \\circ \\sigma \\right) \\mathbb{1}^T = $\n",
    "\n",
    "$\\Large  = \\nabla_{ Z^{[3]}_{0} } \\left( \\mathcal{L} \\circ \\sigma \\right) A^{[2]T}_{0}  = \\sigma'(Z^{[3]}_{0}) \\odot \\left[  \\nabla_{ A^{[3]}_{0} }  \\mathcal{L}  \\right]  \\mathbb{1}^T = $\n",
    "\n",
    "$\\Large = A^{[3]}_{0} \\odot (1 - A^{[3]}_{0}) \\odot \\left[ \\left(\\frac{1}{ A^{[3]}_{0}} \\odot -\\frac{1}{m}Y \\right) + \\left(\\frac{1}{1 - A^{[3]}_{0}} \\odot \\frac{1}{m}(1 - Y) \\right)    \\right]  \\mathbb{1}^T $ \n",
    "\n",
    "$\\Large  = \\left[ \\left(1 - A^{[3]}_{0} \\odot -\\frac{1}{m}Y \\right) + \\left(A^{[3]}_{0} \\odot \\frac{1}{m}(1 - Y) \\right)    \\right] \\mathbb{1}^T$\n",
    "\n",
    "$= \\Large \\frac{1}{m} \\left(A^{[3]}_{0} - Y \\right) \\mathbb{1}^T = \\frac{1}{m} np.sum(A^{[3]}_{0} - Y , axis=1, keepdims=True)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1de64b-23b7-4197-b401-f8e777310715",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  $ \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial W^{[2]}}}_{n_{h}^{[2]} \\times n_{h}^{[1]}} =  \\Large \\frac{1}{m} \\underbrace{np.heaviside(Z^{[2]}_{0}, 0)}_{n_{h}^{[2]} \\times m } \\odot \\left[\\underbrace{W^{[3]T}_{0}}_{n_{h}^{[2]}  \\times n_{y}  } \\underbrace{\\left(A^{[3]}_{0} - Y \\right)}_{n_{y} \\times m} \\right] \\underbrace{A^{[1]T}_{0}}_{m \\times n^{[1]}_{h} }$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8d53b-d9cf-40f1-a9e9-3e1a38ac8ac7",
   "metadata": {},
   "source": [
    "$\\Large \\nabla_{W^{[2]}_{0}} \\mathcal{L}=  \\nabla_{W^{[2]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right]  \\circ ReLU \\circ  \\left[W^{[2]} \\mapsto W^{[2]}A^{[1]} + b^{[2]} \\right] \\right) = $\n",
    "\n",
    "$= \\Large  \\nabla_{Z^{[2]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right]  \\circ ReLU  \\right)A^{[1]T}_{0} = $\n",
    "\n",
    "$= \\Large  np.max(0,Z^{[2]}_{0}) \\odot \\left[\\nabla_{A^{[2]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right] \\right) \\right] A^{[1]T}_{0} =$\n",
    "\n",
    "$= \\Large  np.max(0,Z^{[2]}_{0}) \\odot \\left[W^{[3]T}_{0} \\nabla_{Z^{[3]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\right) \\right] A^{[1]T}_{0} =$\n",
    "\n",
    "$= \\Large  np.max(0,Z^{[2]}_{0}) \\odot \\left[W^{[3]T}_{0} \\frac{1}{m} \\left(A^{[3]}_{0} - Y \\right) \\right] A^{[1]T}_{0}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d382eb-d7d5-4fa9-85b3-47a18d2d0b35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##  $ \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial b^{[2]}}}_{n_{h}^{[2]} \\times 1} =  \\frac{1}{m} np.sum(\\underbrace{np.heaviside(Z^{[2]}_{0}, 0)}_{n_{h}^{[2]} \\times m} \\odot \\left[\\underbrace{W^{[3]T}_{0}}_{n_{h}^{[2]}  \\times n_{y} }  \\underbrace{\\left( A^{[3]}_{0} - Y \\right)}_{n_{y} \\times m} \\right], axis = 1, keepdims=True)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03b7267-bf16-47b6-8daf-e8ec8b1e7cb2",
   "metadata": {},
   "source": [
    "$\\Large \\nabla_{b^{[2]}_{0}} \\mathcal{L}=  \\nabla_{b^{[2]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right]  \\circ ReLU \\circ  \\left[b^{[2]} \\mapsto W^{[2]}A^{[1]} + b^{[2]} \\right] \\right) = $\n",
    "\n",
    "$= \\Large  \\nabla_{Z^{[2]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right]  \\circ ReLU  \\right)\\mathbb{1}^T= $\n",
    "\n",
    "$= \\Large  np.max(0,Z^{[2]}_{0}) \\odot \\left[\\nabla_{A^{[2]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right] \\right) \\right] \\mathbb{1}^T =$\n",
    "\n",
    "$= \\Large  np.max(0,Z^{[2]}_{0}) \\odot \\left[W^{[3]T}_{0} \\nabla_{Z^{[3]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\right) \\right] \\mathbb{1}^T =$\n",
    "\n",
    "$= \\Large  np.max(0,Z^{[2]}_{0}) \\odot \\left[W^{[3]T}_{0} \\frac{1}{m} \\left(A^{[3]}_{0} - Y \\right) \\right] \\mathbb{1}^T = $\n",
    "\n",
    "$ = \\Large  \\frac{1}{m} np.sum( np.max(0,Z^{[2]}_{0}) \\odot \\left[W^{[3]T}_{0} \\left(A^{[3]}_{0} - Y \\right) \\right], axis = 1, keepdims=True)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a95bd-7eb0-40b9-8256-7fc5371362a6",
   "metadata": {},
   "source": [
    "##  $ \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial W^{[1]}}}_{n_{h}^{[1]} \\times n_{x}} =                                                                                                             \\frac{1}{m}  \\underbrace{np.heaviside(Z^{[1]}_{0}, 0)}_{n_{h}^{[1]} \\times m } \\odot \\left[\\underbrace{W^{[2]T}_{0}}_{n_{h}^{[1]} \\times n_{h}^{[2]}} \\left[ \\underbrace{np.heaviside(Z^{[2]}_{0}, 0)}_{n_{h}^{[2]} \\times m } \\odot  \\underbrace{W^{[3]T}_{0}}_{n_{h}^{[2]} \\times n_{y}}  \\underbrace{\\left(A^{[3]}_{0} - Y \\right)}_{n_y \\times m } \\right]  \\right] \\underbrace{A^{[0]T}_{0}}_{m \\times n_x}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1aac9f-7bbe-4014-a85a-dd60e035cf69",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "$\\Large \\nabla_{W^{[1]}_{0}} \\mathcal{L} =  \\nabla_{W^{[1]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right]  \\circ ReLU \\circ  \\left[A^{[1]} \\mapsto W^{[2]}A^{[1]} + b^{[2]} \\right] \\circ ReLU \\circ   \\left[W^{[1]} \\mapsto W^{[1]}A^{[0]} + b^{[1]} \\right] \\right) = $\n",
    "\n",
    "$= \\Large  \\nabla_{Z^{[1]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right]  \\circ ReLU \\circ  \\left[A^{[1]} \\mapsto W^{[2]}A^{[1]} + b^{[2]} \\right] \\circ ReLU \\right) A^{[0]T}_{0} = $\n",
    "\n",
    "$= \\Large np.max(0, Z^{[1]}_{0}) \\odot \\left[ \\nabla_{A^{[1]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right]  \\circ ReLU \\circ  \\left[A^{[1]} \\mapsto W^{[2]}A^{[1]} + b^{[2]} \\right]  \\right) \\right] A^{[0]T}_{0} =$\n",
    "\n",
    "$= \\Large np.max(0, Z^{[1]}_{0}) \\odot \\left[W^{[2]T}_{0} \\nabla_{Z^{[2]}_{0}} \\left( \\mathcal{L} \\circ \\sigma \\circ \\left[A^{[2]} \\mapsto W^{[3]}A^{[2]} + b^{[3]} \\right]  \\circ ReLU  \\right) \\right] A^{[0]T}_{0} = $\n",
    "\n",
    "$= \\Large np.max(0, Z^{[1]}_{0}) \\odot \\left[W^{[2]T}_{0}  np.max(0,Z^{[2]}_{0}) \\odot \\left[W^{[3]T}_{0} \\frac{1}{m} \\left(A^{[3]}_{0} - Y \\right) \\right]  \\right] A^{[0]T}_{0} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32eb43-d848-4acd-9d28-2479a6e2c825",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  $ \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial b^{[1]}}}_{n_{h}^{[1]} \\times 1} =                                                                                                             \\frac{1}{m} np.sum \\left( \\underbrace{np.heaviside( Z^{[1]}_{0}, 0)}_{n_{h}^{[1]} \\times m } \\odot \\left[\\underbrace{W^{[2]T}_{0}}_{n_{h}^{[1]} \\times n_{h}^{[2]}} \\left[ \\underbrace{np.heaviside(Z^{[2]}_{0}, 0)}_{n_{h}^{[2]} \\times m } \\odot  \\underbrace{W^{[3]T}_{0}}_{n_{h}^{[2]} \\times n_{y}}  \\underbrace{\\left(A^{[3]}_{0} - Y \\right)}_{n_y \\times m } \\right]  \\right], axis=1, keepdim=True \\right)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c2198-77c4-4793-bb3a-c9d02a942ee1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Реализация NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "479f3ace-0c5e-47ef-b996-373c95a671a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(over='ignore')\n",
    "\n",
    "def ReLU(z):\n",
    "    return z * (z > 0)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 /(1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def dictionary_to_vector(parameters):\n",
    "    keys = []\n",
    "    count = 0\n",
    "    for key in [\"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"]:\n",
    "        \n",
    "        # flatten parameter\n",
    "        new_vector = np.reshape(parameters[key], (-1, 1))\n",
    "        keys = keys + [key] * new_vector.shape[0]\n",
    "        \n",
    "        if count == 0:\n",
    "            theta = new_vector\n",
    "        else:\n",
    "            theta = np.concatenate((theta, new_vector), axis=0)\n",
    "        count = count + 1\n",
    "\n",
    "    return theta, keys\n",
    "\n",
    "def vector_to_dictionary(theta):\n",
    "    parameters = {}\n",
    "    parameters[\"W1\"] = theta[: 640].reshape((10, 64))\n",
    "    parameters[\"b1\"] = theta[640: 650].reshape((10, 1))\n",
    "    parameters[\"W2\"] = theta[650: 700].reshape((5, 10))\n",
    "    parameters[\"b2\"] = theta[700: 705].reshape((5, 1))\n",
    "    parameters[\"W3\"] = theta[705: 710].reshape((1, 5))\n",
    "    parameters[\"b3\"] = theta[710: 711].reshape((1, 1))\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def gradients_to_vector(gradients):\n",
    "    count = 0\n",
    "    for key in [\"dW1\", \"db1\", \"dW2\", \"db2\", \"dW3\", \"db3\"]:\n",
    "        new_vector = np.reshape(gradients[key], (-1, 1))\n",
    "        \n",
    "        if count == 0:\n",
    "            theta = new_vector\n",
    "        else:\n",
    "            theta = np.concatenate((theta, new_vector), axis=0)\n",
    "        count = count + 1\n",
    "\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "7407aa4e-1b33-4c4c-b3a5-6e25d70c99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers_dims):\n",
    "        self.layers_dims = layers_dims\n",
    "        \n",
    "        \n",
    "    def initialize_parameters(self):\n",
    "        W1 = np.random.randn(self.layers_dims[1], self.layers_dims[0])*0.01\n",
    "        W2 = np.random.randn(self.layers_dims[2], self.layers_dims[1])*0.01\n",
    "        W3 = np.random.randn(self.layers_dims[3], self.layers_dims[2]) *0.01\n",
    "\n",
    "        b1 = np.zeros((self.layers_dims[1], 1))\n",
    "        b2 = np.zeros((self.layers_dims[2], 1))\n",
    "        b3 = np.zeros((self.layers_dims[3], 1))\n",
    "        \n",
    "        parameters = {\"W1\": W1 , \n",
    "                      \"b1\": b1,\n",
    "                      \"W2\": W2,\n",
    "                      \"b2\": b2,\n",
    "                      \"W3\": W3, \n",
    "                      \"b3\": b3}        \n",
    "        \n",
    "        return parameters\n",
    "    \n",
    "    def forward_pass(self, X, parameters):\n",
    "        W1 = parameters['W1']\n",
    "        b1 = parameters['b1']\n",
    "        W2 = parameters['W2']\n",
    "        b2 = parameters['b2']\n",
    "        W3 = parameters['W3']\n",
    "        b3 = parameters['b3']\n",
    "        \n",
    "        \n",
    "        Z1 = np.matmul(W1, X) + b1\n",
    "        A1 = ReLU(Z1)\n",
    "        Z2 = np.matmul(W2, A1) + b2\n",
    "        A2 = ReLU(Z2)\n",
    "        Z3 = np.matmul(W3, A2) + b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        \n",
    "        cache = {\"Z1\": Z1, \"A1\": A1,\n",
    "                  \"Z2\": Z2, \"A2\": A2, \n",
    "                  \"Z3\": Z3, \"A3\": A3}\n",
    "        return A3, cache\n",
    "    \n",
    "    \n",
    "    def backward_pass(self, cache, parameters, X, Y):\n",
    "        Z3 = cache['Z3']\n",
    "        A3 = cache['A3']\n",
    "        Z2 = cache['Z2']\n",
    "        A2 = cache['A2']\n",
    "        Z1 = cache['Z1']\n",
    "        A1 = cache['A1']\n",
    "        \n",
    "        W1 = parameters['W1']\n",
    "        W2 = parameters['W2']\n",
    "        W3 = parameters['W3']\n",
    "        b1 = parameters['b1']\n",
    "        b2 = parameters['b2']\n",
    "        b3 = parameters['b3']\n",
    "\n",
    "        \n",
    "        m = X.shape[1]\n",
    "        \n",
    "\n",
    "        dZ3 = A3 - Y\n",
    "        dW3 = 1/m * np.matmul(dZ3, A2.T)\n",
    "        db3 = 1/m * np.sum(dZ3, axis=1, keepdims=True)\n",
    "        \n",
    "        dZ2 = np.heaviside(Z2, 0)* (np.matmul(W3.T, dZ3))\n",
    "        dW2 = 1/m * np.matmul(dZ2, A1.T)\n",
    "        db2 = 1/m * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        \n",
    "        dZ1 = np.heaviside(Z1, 0) * np.matmul(W2.T ,dZ2)\n",
    "        dW1 = 1/m * np.matmul(dZ1, X.T)\n",
    "        db1 = 1/m * np.sum(dZ1, axis = 1, keepdims=True)\n",
    "        \n",
    "        \n",
    "        assert dW3.shape == W3.shape\n",
    "        assert dW2.shape == W2.shape\n",
    "        assert dW1.shape == W1.shape\n",
    "        assert db3.shape == b3.shape\n",
    "        assert db2.shape == b2.shape\n",
    "        assert db1.shape == b1.shape\n",
    "        \n",
    "        \n",
    "        gradients = {\n",
    "            \"dW3\": dW3, \"db3\": db3, \n",
    "            \"dW2\": dW2, \"db2\": db2, \n",
    "            \"dW1\":dW1,  \"db1\": db1\n",
    "        }\n",
    "        return gradients\n",
    "    \n",
    "    def update_parameters(self, parameters, gradients, learning_rate):\n",
    "        W1 = copy.deepcopy(parameters['W1'])\n",
    "        b1 = copy.deepcopy(parameters['b1'])\n",
    "        W2 = copy.deepcopy(parameters['W2'])\n",
    "        b2 = copy.deepcopy(parameters['b2'])\n",
    "        W3 = copy.deepcopy(parameters['W3'])\n",
    "        b3 = copy.deepcopy(parameters['b3'])\n",
    "        \n",
    "        dW1 = gradients['dW1']\n",
    "        db1 = gradients['db1']\n",
    "        dW2 = gradients['dW2']\n",
    "        db2 = gradients['db2']\n",
    "        dW3 = gradients['dW3']\n",
    "        db3 = gradients['db3']\n",
    "        \n",
    "        W1 = W1 - learning_rate*dW1\n",
    "        b1 = b1 - learning_rate*db1\n",
    "        W2 = W2 - learning_rate*dW2\n",
    "        b2 = b2 - learning_rate*db2\n",
    "        W3 = W3 - learning_rate*dW3\n",
    "        b3 = b3 - learning_rate*db3\n",
    "        \n",
    "        parameters = {\"W1\": W1 , \n",
    "                      \"b1\": b1,\n",
    "                      \"W2\": W2,\n",
    "                      \"b2\": b2,\n",
    "                      \"W3\": W3, \n",
    "                      \"b3\": b3}\n",
    "        return parameters\n",
    "    \n",
    "    def compute_loss(self, Y, A3):\n",
    "        m = Y.shape[1]\n",
    "        return -1/m *(np.matmul(Y, np.log(A3).T) + np.matmul((1 - Y), np.log(1 - A3).T))[0][0]\n",
    "    \n",
    "   \n",
    "    def train(self, num_iterations, X_train, y_train, X_test, y_test, print_loss=True, learning_rate=0.01):\n",
    "        parameters = self.initialize_parameters()\n",
    "        losses_train = []\n",
    "        losses_test = []\n",
    "        for i in range(num_iterations):\n",
    "            A3, cache = self.forward_pass(X_train, parameters)\n",
    "            gradients = self.backward_pass(cache, parameters, X_train, y_train)\n",
    "            parameters = self.update_parameters(parameters, gradients, learning_rate=learning_rate)\n",
    "            loss_train = self.compute_loss(y_train, A3)\n",
    "            loss_test = self.compute_loss(y_test, self.forward_pass(X_test, parameters)[0])\n",
    "            losses_train.append(loss_train)\n",
    "            losses_test.append(loss_test)\n",
    "            if print_loss and i % 500 == 0:\n",
    "                print(f\"loss_train after {i + 1} iterations = {round(loss_train,4)}\")\n",
    "        return losses_train, losses_test       \n",
    "    \n",
    "    def predict(self, parameters, x):\n",
    "        return (self.forward_pass(x, parameters)[0] < 0.5) + 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    def gradient_check(self, parameters, gradients, X, Y, epsilon=1e-7, print_msg=True):\n",
    "        parameters_values, _ = dictionary_to_vector(parameters)\n",
    "        grad = gradients_to_vector(gradients)\n",
    "        num_parameters = parameters_values.shape[0]\n",
    "        J_plus = np.zeros((num_parameters, 1))\n",
    "        J_minus = np.zeros((num_parameters, 1))\n",
    "        gradapprox = np.zeros((num_parameters, 1))\n",
    "\n",
    "        for i in range(num_parameters):\n",
    "\n",
    "            theta_plus = np.copy(parameters_values)\n",
    "            theta_plus[i] = theta_plus[i] + epsilon\n",
    "            out, cache = self.forward_pass(X, vector_to_dictionary(theta_plus))\n",
    "            J_plus[i] =  self.compute_loss(Y, out)\n",
    "\n",
    "            theta_minus = np.copy(parameters_values)\n",
    "            theta_minus[i] = theta_minus[i] - epsilon\n",
    "            out, cache = self.forward_pass(X, vector_to_dictionary(theta_minus))\n",
    "            J_minus[i]= self.compute_loss(Y, out)\n",
    "\n",
    "            gradapprox[i] = (J_plus[i] - J_minus[i]) / (2*epsilon)\n",
    "\n",
    "        numerator = np.linalg.norm(grad - gradapprox)\n",
    "        denominator =  np.linalg.norm(grad) +  np.linalg.norm(gradapprox)\n",
    "        difference = numerator/denominator\n",
    "        \n",
    "        if print_msg:\n",
    "            if difference > 2e-7:\n",
    "                print (\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n",
    "            else:\n",
    "                print (\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n",
    "\n",
    "        return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "8cb8a782-81e2-488f-9a14-bd218b9edfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork(layers_dims=[64, 10, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "21ae8da9-cbdc-4cca-87ae-5dd43ee21e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses_train, losses_test = NN.train(num_iterations=2000, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, print_loss=False, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "94e99def-0489-4723-ae19-7e8b4612aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mYour backward propagation works perfectly fine! difference = 1.8316815974957075e-07\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "out, cache = NN.forward_pass(X_train, parameters)\n",
    "cost = NN.compute_loss(y_train, out) \n",
    "gradients = NN.backward_pass(cache, parameters, X_train, y_train)\n",
    "difference = NN.gradient_check(parameters, gradients, X_train, y_train, 1e-7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "bfd1d5bf-2366-4012-bc3d-f3481ba16c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA21klEQVR4nO3deXhU5dn48e+dyb5ACAlrQMJOkEUIi6gIVgG1vm6ouK+1tGqr1rb21ba2/lqttra1opSKL651V6yiolVEFISA7PtOCEsIZANCksn9++OcwBAnYRIyM1nuz3Wda855zvPMuXOSzD1nex5RVYwxxpjqIsIdgDHGmMbJEoQxxhi/LEEYY4zxyxKEMcYYvyxBGGOM8Ssy3AE0pNTUVO3WrVu4wzDGmCZj8eLF+1Q1zd+6ZpUgunXrRnZ2drjDMMaYJkNEttW0zk4xGWOM8SuoCUJEJojIOhHZKCL3+1n/cxFZ6k4rRcQrIimBtDXGGBNcQUsQIuIBpgDnA5nA1SKS6VtHVR9X1cGqOhj4FfCFqu4PpK0xxpjgCuY1iOHARlXdDCAirwIXA6trqH818O96tjXGNFPl5eXk5ORQWloa7lCatNjYWNLT04mKigq4TTATRGdgh89yDjDCX0URiQcmAHfWta0xpnnLyckhKSmJbt26ISLhDqdJUlXy8/PJyckhIyMj4HbBvAbh7zdZU8+AFwFfqer+urYVkdtFJFtEsvPy8uoRpjGmMSstLaVt27aWHE6CiNC2bds6H4UFM0HkAF18ltOB3BrqTuLY6aU6tVXVaaqapapZaWl+b+U1xjRxlhxOXn32YTATxCKgl4hkiEg0ThJ4r3olEWkNnA3MrGvbhlDureSN7B0s3rb/xJWNMaYFCVqCUNUKnGsKHwNrgNdVdZWITBaRyT5VLwVmq+rBE7UNRpyRWk75f+5j/ecvBuPtjTGmyQrqk9SqOguYVa1sarXlGcCMQNoGg0TGcL7nG5btLgN+GuzNGWOaoMTEREpKSoL2/jNmzGDcuHF06tSpTu2mTp1KfHw8N9xwQ1DialZdbdRXXmI/0gvXU1mpRETYuU5jTGjNmDGDU0891W+C8Hq9eDwev+0mT57st7yhWIIAytsPpG/hfLbv2Ue3jnah25jG6nf/WcXq3KIGfc/MTq347UX9A6qrqvziF7/gww8/RER48MEHueqqq9i1axdXXXUVRUVFVFRU8MwzzzBq1ChuvfVWsrOzERFuueUW7rnnnu+855tvvkl2djbXXnstcXFxzJ8/n379+nHLLbcwe/Zs7rzzToqLi5k2bRplZWX07NmTF198kfj4eB566CESExO57777GDNmDCNGjODzzz+noKCA6dOnc9ZZZ53UvrG+mIDEjGF4RMlduzDcoRhjGrG3336bpUuXsmzZMj799FN+/vOfs2vXLl555RXGjx9/dN3gwYNZunQpO3fuZOXKlaxYsYKbb77Z73tOnDiRrKwsXn75ZZYuXUpcXBzgPNg2b948Jk2axGWXXcaiRYtYtmwZ/fr1Y/r06X7fq6KigoULF/K3v/2N3/3udyf989oRBNC+70iYDYe3LQIuDHc4xpgaBPpNP1jmzZvH1VdfjcfjoX379px99tksWrSIYcOGccstt1BeXs4ll1zC4MGD6d69O5s3b+auu+7iwgsvZNy4cXXa1lVXXXV0fuXKlTz44IMUFBRQUlLC+PHj/ba57LLLABg6dChbt26t989ZxY4ggNiUdPKlDXF5K8IdijGmEVP1/6zv6NGjmTt3Lp07d+b666/nhRdeoE2bNixbtowxY8YwZcoUbrvttjptKyEh4ej8TTfdxFNPPcWKFSv47W9/W+MDbzExMQB4PB4qKirqtD1/LEG4dif0pcOhdeEOwxjTiI0ePZrXXnsNr9dLXl4ec+fOZfjw4Wzbto127drxgx/8gFtvvZUlS5awb98+Kisrufzyy3n44YdZsmRJje+blJREcXFxjeuLi4vp2LEj5eXlvPzyy8H40fyyU0yu0tQB9C1ewP4DB0hp0ybc4RhjGqFLL72U+fPnM2jQIESExx57jA4dOvD888/z+OOPExUVRWJiIi+88AI7d+7k5ptvprKyEoBHHnmkxve96aabmDx58tGL1NU9/PDDjBgxglNOOYUBAwbUmkwaktR0yNQUZWVlaX1HlFv9+WtkfnE7y8e9xsBRExo4MmNMfa1Zs4Z+/fqFO4xmwd++FJHFqprlr76dYnJ16DcSgJItNmSpMcaAnWI6KqXDKewjmai9y8IdijGmmbrjjjv46quvjiv76U9/WuMtsOFmCcJHTlwf2hWvCXcYxphmasqUKeEOoU7sFJOPQ21PJd2bQ+nBhn1S0xhjmiJLED6iu2bhESVnzYJwh2KMMWFnCcJHx8wzASja8HWYIzHGmPCzBOGjU+cubKc9UbtqfqDFGGNaCksQPkSEHfGn0ql4BTSj50OMMScnMTExqO8/Y8YMcnNrGpG5dnPmzOHrr4Nz1sMSRDWl7U6jre6ndP/2cIdijGkhGmuCsNtcq4nvMRK2Qu7KL+l+9inhDscY4+vD+2F3A3eq2WEAnP9oQFVDNR7E6tWruffeeykpKSE1NZUZM2bQsWNHnnzySaZOnUpkZCSZmZk8+uijTJ06FY/Hw0svvcQ//vGPkx4DwldQE4SITAD+DniAZ1X1O78FERkD/A2IAvap6tlu+VagGPACFTU9Ct7QuvUfzpFPozi8eQGcfV0oNmmMaSJ8x4PYt28fw4YNY/To0UfHg3jggQfwer0cOnTouPEgAAoKCvy+58SJE3nqqaf485//TFZWFuXl5dx1113MnDmTtLQ0XnvtNR544AGee+45Hn30UbZs2UJMTAwFBQUkJyczefLko4MGNbSgJQgR8QBTgPOAHGCRiLynqqt96iQDTwMTVHW7iLSr9jZjVXVfsGL0p0ObViyX7rTa+20oN2uMCUSA3/SDJRTjQaxbt46VK1dy3nnnAc6Qox07dgRg4MCBXHvttVxyySVccsklwfoxjwrmNYjhwEZV3ayqZcCrwMXV6lwDvK2q2wFUdW8Q4wmIiLC71QA6H14HFWXhDscY04iEYjwIVaV///4sXbqUpUuXsmLFCmbPng3ABx98wB133MHixYsZOnRog4z5UJtgJojOwA6f5Ry3zFdvoI2IzBGRxSJyg886BWa75bfXtBERuV1EskUkOy8vr0ECL+84lGjKOZxj/TIZY44JxXgQffr0IS8v72i33+Xl5axatYrKykp27NjB2LFjeeyxx46OLneisSRORjCvQYifsurpNxIYCnwPiAPmi8gCVV0PnKGque5pp09EZK2qzv3OG6pOA6aB0913QwSe3HsUrIM9q+fRrduwhnhLY0wzEKrxIN58801+8pOfUFhYSEVFBXfffTe9e/fmuuuuo7CwEFXlnnvuITk5mYsuuoiJEycyc+bMBr9IHbTxIETkdOAhVR3vLv8KQFUf8alzPxCrqg+5y9OBj1T1jWrv9RBQoqp/rm2bJzMehK+9hYepfKIfJR1G0vNHr570+xlj6s/Gg2g4jWk8iEVALxHJEJFoYBLwXrU6M4GzRCRSROKBEcAaEUkQkSQ3+ARgHLAyiLEep13rOFZH9KFNvj1RbYxpuYJ2iklVK0TkTuBjnNtcn1PVVSIy2V0/VVXXiMhHwHKgEudW2JUi0h14R0SqYnxFVT8KVqz+7E0ZQtv8BVCYA63TQ7lpY0wzZeNB+FDVWcCsamVTqy0/DjxerWwzMCiYsZ2InDIK8p+mZP2XJA67OpyhGNPiqSruF8YmLZzjQdTncoJ1tVGDrv1GUKxxFKz7ItyhGNOixcbGkp+fX68POONQVfLz84mNja1TO+tqowaDTkkhW3uRufObcIdiTIuWnp5OTk4ODXUbe0sVGxtLenrdTpdbgqhBfHQkWxMGMfrwi3BoP8SnhDskY1qkqKgoMjIywh1Gi2SnmGpRnj4SAO+2+WGOxBhjQs8SRC3S+oziiEZyYI1dhzDGtDyWIGoxOKMDy7U7us2GIDXGtDyWIGrRJSWOlZ7+pBSuhrKD4Q7HGGNCyhJELUSEovbD8OCFnJPvwsMYY5oSSxAnkNDzTCo0gsMb5oQ7FGOMCSlLECcwoHs6y7U7R9Z/Hu5QjDEmpCxBnMDA9GTm66m0yl8OpUXhDscYY0LGEsQJxEV72NVmOBF4Ybs9D2GMaTksQQQgsdcojmgUFRvtNJMxpuWwBBGAoT06kV3ZmyN2odoY04JYggjA8G4pfK39STiwBg7uC3c4xhgTEpYgAtA6Poqdye7Y1Fu+Myy2McY0S5YgAtSm53BKNA7vZuuXyRjTMgQ1QYjIBBFZJyIbReT+GuqMEZGlIrJKRL6oS9tQyurengWVfanYYBeqjTEtQ9AShIh4gCnA+UAmcLWIZFarkww8DfyPqvYHrgi0bagNz0jhy8qBxBRvg/xN4QzFGGNCIphHEMOBjaq6WVXLgFeBi6vVuQZ4W1W3A6jq3jq0Dam0pBg2JZ/uLGz8bzhDMcaYkAhmgugM7PBZznHLfPUG2ojIHBFZLCI31KEtACJyu4hki0h2sIck7NKjP9tpj278NKjbMcaYxiCYCUL8lFUfdTwSGApcCIwHfi0ivQNs6xSqTlPVLFXNSktLO5l4T2h4RgqfVQxCN38B5aVB3ZYxxoRbMBNEDtDFZzkdyPVT5yNVPaiq+4C5wKAA24bciIy2zKkcRIS3FLZ9Fe5wjDEmqIKZIBYBvUQkQ0SigUnAe9XqzATOEpFIEYkHRgBrAmwbcp2S49jTZhjlRNl1CGNMsxe0BKGqFcCdwMc4H/qvq+oqEZksIpPdOmuAj4DlwELgWVVdWVPbYMVaF1m9OvON9kM3fBLuUIwxJqgig/nmqjoLmFWtbGq15ceBxwNp2xic0TOVzxYN4sz8F+HANmhzSrhDMsaYoLAnqevo9O5tmasDnYWNdhRhjGm+LEHUUev4KBI6ZbLL0xHWfRTucIwxJmgsQdTDmb1S+aDsNHTLF3CkONzhGGNMUFiCqIcze6bxcUUW4i0De2jOGNNMWYKohyGnJLMqsi8HI5NhbaO7jm6MMQ3CEkQ9xER6yMpIY54MhQ0fg7c83CEZY0yDswRRT2f2bMubBwdBaaE9VW2MaZYsQdTT2b3b8WXlACoiYu00kzGmWbIEUU+92yfSNjmZlbFDYO0HoH77EjTGmCbLEkQ9iQhj+qTxRslAKMqBXcvCHZIxxjQoSxAnYWyfdnxQdhqVEgmr3gl3OMYY06AsQZyEUT3bciiyNZuTsmDV23aayRjTrFiCOAnx0ZGM7N6Wt8qGQ8F22Lkk3CEZY0yDsQRxksb2SePlggFoRLRzFGGMMc2EJYiTNLZPO4pIIKft6c51iMrKcIdkjDENwhLESeqWmkD31AQ+qDwdinZCzsJwh2SMMQ3CEkQDOKdvO/65uw8aGQsr7TSTMaZ5CGqCEJEJIrJORDaKyP1+1o8RkUIRWepOv/FZt1VEVrjl2cGM82SNP7UDB7wx7G53Fqx+F7wV4Q7JGGNOWtAShIh4gCnA+UAmcLWIZPqp+qWqDnan31dbN9YtzwpWnA1hSNc2pCZG84GeASV7YPOccIdkjDEnLZhHEMOBjaq6WVXLgFeBi4O4vbDxRAjnZbbnqZ090dhkWPZKuEMyxpiTFswE0RnY4bOc45ZVd7qILBORD0Wkv0+5ArNFZLGI3B7EOBvEuP4dKCiLYGeXC52+mUoLwx2SMcaclGAmCPFTVv1R4yXAKao6CPgH8K7PujNUdQjOKao7RGS0342I3C4i2SKSnZeX1wBh18+oHm1JjInkHe/ZUFFqXW8YY5q8YCaIHKCLz3I6kOtbQVWLVLXEnZ8FRIlIqruc677uBd7BOWX1Hao6TVWzVDUrLS2t4X+KAMVEehjbtx0ztrZBU/vA0n+HLRZjjGkIwUwQi4BeIpIhItHAJOA93woi0kFExJ0f7saTLyIJIpLklicA44CVQYy1QYzv3578Q+Xs6Hox7FgA+ZvCHZIxxtRb0BKEqlYAdwIfA2uA11V1lYhMFpHJbrWJwEoRWQY8CUxSVQXaA/Pc8oXAB6r6UbBibShj+rQjOjKCN8rOAImAZXYUYYxpukSbUQ+kWVlZmp0d3kcmbn8hm6U7Cvim6zPI3tVw9wrwRIY1JmOMqYmILK7pUYITHkGIyBU+p3seFJG3RWRIQwfZXFw0qBN7i4+wLn0iFOfCho/DHZIxxtRLIKeYfq2qxSJyJjAeeB54JrhhNV3f69eOuCgPLx3oC0mdIPu5cIdkjDH1EkiC8LqvFwLPqOpMIDp4ITVt8dGRnJfZng9W5uE97QbY+F/YvyXcYRljTJ0FkiB2isg/gSuBWSISE2C7FuuiQZ04cKicBW0udC5WL3k+3CEZY0ydBfJBfyXOnUgTVLUASAF+HsygmrrRvVNpFRvJWxsqoc/5sORFqCgLd1jGGFMngSSIjji3mW4QkTHAFTi3npoaxER6mHBqB2av2kPZ4Bvh0D5Y896JGxpjTCMSSIJ4C/CKSE9gOpABWG90J3DRoE6UHKng07L+kNIdvpka7pCMMaZOAkkQle5Db5cBf1PVe3COKkwtRvVIpX2rGN5akgsjfww5i2CHHXgZY5qOQBJEuYhcDdwAvO+WRQUvpObBEyFcNiSdOevz2NvzMohNhvlPhTssY4wJWCAJ4mbgdOAPqrpFRDKAl4IbVvNw+ZB0vJXKzJWFMPQmWPMfOLAt3GEZY0xATpggVHU1cB+wQkROBXJU9dGgR9YM9GyXyGldk3lzcQ46/AfOLa/f/DPcYRljTEAC6WpjDLABZ/jQp4H1NY3NYL5r4tB01u0pZkVxIvS/FJa8YIMJGWOahEBOMf0FGKeqZ6vqaJzuNv4a3LCaj+8P7ERMZARvLs6B0++EsmJY9Gy4wzLGmBMKJEFEqeq6qgVVXY9dpA5Y67goxvfvwMyluZSmDYCe58H8KVB2MNyhGWNMrQJJENkiMl1ExrjTv4DFwQ6sOblqWBcKD5fz4cpdcPYv4FA+ZP9fuMMyxphaBZIgfgSsAn4C/BRYDUyutYU5zqgebememsBLC7ZDl+GQMRq+fhLKS8MdmjHG1CiQu5iOqOoTqnqZql6qqn9V1SOhCK65EBGuGdGVxdsOsGZXEYz+OZTsgW9fDHdoxhhToxoThIisEJHlNU2hDLI5mDg0nZjICF5asA26nQVdRsK8v1knfsaYRqu2I4jvAxfVMp2QiEwQkXUislFE7vezfoyIFIrIUnf6TaBtm5rk+Gi+P7AT7367k5Iyr3MtoigHFs8Id2jGGONXjQlCVbfVNp3ojUXEg/PsxPlAJnC1iGT6qfqlqg52p9/XsW2Tct3Irhws8/LOtzuhxznOkcTcx+BISbhDM8aY7wjmwD/DgY2qullVy4BXgYtD0LbRGtwlmf6dWvHygm0owLkPwcE8WGAjuBpjGp9gJojOwA6f5Ry3rLrTRWSZiHwoIv3r2BYRuV1EskUkOy8vryHiDhoR4YbTT2Ht7mLmb8qH9Czo+33njqaD+eEOzxhjjhPMBCF+yrTa8hLgFFUdBPwDeLcObZ1C1WmqmqWqWWlpafWNNWQuHtyZ1MRonp3njlN9zq+hrATmPRHewIwxpppA+mLydzfTlyLyVxFpW0vTHKCLz3I6kOtbQVWLVLXEnZ8FRIlIaiBtm6rYKA/Xj+zGZ2v3snFvMbTrC4OugYXTYP+WcIdnjDFHBXIE8SHwAXCtO/0HmAvsBmbU0m4R0EtEMkQkGpgEHDfupoh0EBFx54e78eQH0rYpu25kV2IiI5g+b6tTcM6DEBEFsx8Ma1zGGOMrkARxhqr+SlVXuNMDwBhV/RPQraZG7ih0dwIfA2uA11V1lYhMFpGqJ7EnAitFZBnwJDBJHX7b1veHbGzaJsZw2ZB03l6SQ37JEWjVEUb/DNa+D5s+D3d4xhgDBJYgEkVkRNWC+00/0V2sqK2hqs5S1d6q2kNV/+CWTVXVqe78U6raX1UHqepIVf26trbNya1nduNIRaXT/QbAyDugTTf46H7wloc1NmOMgcASxG3AsyKyRUS2As8Ct4lIAvBIMINrznq2S2JsnzSen7+VQ2UVEBUL4/8IeWth0fRwh2eMMQH1xbRIVQcAg4HBqjrQLTuoqq8HPcJm7I6xPdl/sIxXvnGPIvpcAN3Hwud/hOLd4Q3OGNPiBXIXU2sReQL4L/CpiPxFRFoHP7TmL6tbCqd3b8u0uZspLfeCCFz4F6gohQ9/Ee7wjDEtXCCnmJ4DioEr3akIsMEMGshd5/Rkb/ER3sh2nwts28Ppp2n1TFg7K7zBGWNatEASRA9V/a3b7cVmVf0d0D3YgbUUp/doy9BT2vDMnE2UVVQ6hWf8FNr1h1n3QWlReAM0xrRYgSSIwyJyZtWCiJwBHA5eSC2LiHDnOT3JLSzlnW9znEJPFPzPk1CUC//9fXgDNMa0WIEkiMnAFBHZ6t7F9BTww6BG1cKM6Z3GwPTW/OOzjceOItKzYOSPYNG/YNNn4Q3QGNMiBXIX0zK3r6SBwEBVPQ04J+iRtSAiws/G9SHnwGH+vXD7sRXf+w2k9oF3fwyH9ocvQGNMixRwZ31uv0lVJ8TvDVI8LdboXqmM7J7CPz7bwMEj7vOHUXFw2TSnS/BZ94U3QGNMi1Pf3lz99bZqToKI8IsJfdlXUsZz83w67es0GMb8Cla+BcvfCFt8xpiWp74Jwm/X2+bkDOnahnGZ7Zk2dzP7D/qMVX3G3dBlBHxwL+RvClt8xpiWpcYEISLFIlLkZyoGOoUwxhblvvF9OFhWwZTPNx4r9ETC5dMhwgOv3wjldhOZMSb4ahuTOklVW/mZklQ1MpRBtiS92ydxxdAuPP/1Vjbl+YxVndwFLvsX7FkBs34evgCNMS1GMEeUM/V03/g+xEZ5+MMHa45f0es8OOtn8O2L8O3L4QnOGNNiWIJohNKSYvjJ93ry2dq9zFm39/iVY/4Xup0F798DOdnhCdAY0yJYgmikbhqVQUZqAg+/v5pyb+WxFZ5IuGIGJHWAV6+BwpywxWiMad4sQTRS0ZERPHhhPzblHeSF+duOX5mQCte8BmWH4N+ToOxgeII0xjRrQU0QIjJBRNaJyEYRub+WesNExCsiE33KtorIChFZKiIt8lzKOX3bcXbvNJ6YvY5dhdXuXGrXD674P9izCt6+HSq94QnSGNNsBS1BiIgHmAKcD2QCV4tIZg31/oQz/nR1Y1V1sKpmBSvOxkxEePjiU/Gq8tuZfobk7nWeMwrd2ved8SPUHk8xxjScYB5BDAc2ul2ElwGvAhf7qXcX8Baw18+6Fq9r23juPrc3s1fv4eNVfkaZG/kjGPUTWPQszHk09AEaY5qtYCaIzsAOn+Uct+woEekMXApM9dNegdkislhEbq9pIyJyu4hki0h2Xl5eA4Td+Nx6ZgZ9OyTx25mrKC4t/26F834Pg6+DLx6Fhf8KfYDGmGYpmAnCX39N1c+B/A34par6O4F+hqoOwTlFdYeIjPa3EVWdpqpZqpqVlpZ2UgE3VlGeCB69fCB7ikt5/ON1360gAhf93RnTetbPYekroQ/SGNPsBDNB5ABdfJbTgdxqdbKAV91xJiYCT4vIJQCqmuu+7gXewTll1WIN7pLMzaMyeGH+Nr7auO+7FTyRMPE56D7G6R7825dCHqMxpnkJZoJYBPQSkQwRiQYmAe/5VlDVDFXtpqrdgDeBH6vquyKSICJJACKSAIwDVgYx1ibhFxP60CMtgfveWEbhYT+nmqLi4Op/Q4+xMPNOWPJC6IM0xjQbQUsQqloB3Ilzd9Ia4HVVXSUik0Vk8gmatwfmicgyYCHwgap+FKxYm4rYKA9PXDmYvcVH+N1//NzVBE6SmPRv6HEOvHcXLJoe2iCNMc2GaDO6NTIrK0uzs5v/IxN//WQ9f//vBqZeN4QJp3b0X6m8FF6/ATZ87IwncfYvnWsVxhjjQ0QW1/QogT1J3QTdeU5PBnRuza/eXvHdB+iqRMXCpJdh8LUw5xF4/257mM4YUyeWIJqgKE8Ef580mLKKSn7y72+p8O2ryZcnCi6eAmfeC4tnwGvXW7ccxpiAWYJoorqnJfLHywawaOsB/vLJ+porisC5v4XzH4P1H8L08VCwPXSBGmOaLEsQTdjFgztz9fCuPDNnE59X7xa8uhE/hGted5LDtLGw7evQBGmMabIsQTRxv70ok74dkrj3taXs2H+o9sq9zoMf/BfikuH5i5ynrpvRTQrGmIZlCaKJi43y8PS1Q6ioVH7wQjaHyipqb5DaC277L/T4Hsy6z7nT6XBBSGI1xjQtliCage5piTx1zRDW7ynmZ68vo7LyBEcFcclw9atw3sOwbhb88ywbnc4Y8x2WIJqJs3un8b8X9OPDlbv5x2cbT9wgIgLO+Anc4vay/tx4pzdYr58ntI0xLZIliGbk1jMzuHxIOn/9dD0fLN8VWKP0LPjhl9D/Uud5iX+dA7tbfK8mxhgsQTQrIsIfLj2VrFPacM/rS/lmc35gDeOS4fJn4aqXoXgXTBsDc/4EFUeCGa4xppGzBNHMxEZ5ePbGLLqmxHPbC9ms3V0UeON+34c7FkLmxTDnj/DMGbDp8+AFa4xp1CxBNEPJ8dE8f8tw4qM93PTcInILauiOw5/4FJg4Ha59Cyor4MVL4PUboXBn0OI1xjROliCaqc7JcTx/y3AOHqng+unfkFdcx9NFvc6FHy+AsQ/A+o/gqSz47P9BaR2OSIwxTZoliGasb4dWTL9pGLkFpVz77ALyS+qYJKJi4exfOImi93iY+zg8eRp880+oKAtO0MaYRsMSRDM3PCOF6TdmsS3/ENc++w0HDtbjgz0lA66YAT/4DNr1gw9/AVOGw7cv222xxjRjliBagFE9U/nXDVls3neQ65/7hoJD9fz233ko3PgfuPZNiEmCmT+GJ4c4gxKVlzZs0MaYsLME0UKM7p3GP68byvrdJVz1zwXsLarnB7qI06fTD+c6nf8ltoMP7oUnB8NXT8LhAw0atzEmfIKaIERkgoisE5GNInJ/LfWGiYhXRCbWta0J3Ni+7XjupmHsOHCIK/45/8Sd+9VGxLkucduncMNMaNsTPvk1PJEJ798DeesaLnBjTFgEbchREfEA64HzgBxgEXC1qq72U+8ToBR4TlXfDLRtdS1lyNGTtWT7AW7+v0XEREbw0m0j6N0+qWHeeNcy+GYarHgDvEeg+1jIuhl6nw+R0Q2zDWNMgwrXkKPDgY2qullVy4BXgYv91LsLeAvYW4+2ph6GdG3Daz8ciQJXTJ3PgkCfuD6RjoPgkilw72o459fOUcTrN8ATfeGjX8GeVQ2zHWNMSAQzQXQGdvgs57hlR4lIZ+BSYGpd2/q8x+0iki0i2Xl5eScddEvRt0Mr3po8itTEaK6f/g1vZO84caNAJaTC6PvgnpXOBe1uZzpjTzwzyunGY/7T9uCdMU1AMBOE+Cmrfj7rb8AvVdVbj7ZOoeo0Vc1S1ay0tLS6R9mCdW0bz9s/PoPhGSn8/M3lPPbR2hN3FV4XER7ngvaVL8DP1sGEPzlPZ3/8K/hrpjP86YKpUBRgx4LGmJCKDOJ75wBdfJbTgdxqdbKAV0UEIBW4QEQqAmxrGkDruChm3Dyc38xcydNzNrFxbwl/vnIQrWKjGnZDCW1h5GRn2rcRVr8Dq96Fj34JH90PXYY7F717T4B2mc5FcGNMWAXzInUkzoXm7wE7cS40X6Oqfk9Ei8gM4H33InWd2laxi9T1p6o899VW/jhrDV1T4pl63VD6dGigi9e1yVsPq95xBi7atdQpa90Feo1zEka3MyE6IfhxGNNC1XaROmgJwt3wBTinkTw4dyj9QUQmA6jq1Gp1Z+AmiJranmh7liBO3sIt+7njlSWUlFbwyGUDuOQ0v5d+gqNoF2yY7UybPofygxAR5YxZkTEaup0F6cOcLkCMMQ0ibAki1CxBNIy9RaXc+cq3LNy6n0nDuvDr72eSEBPMs5F+VByBbV/BlrnOlPstaCVExkKXEdD1dOgyDDpnOeNZGGPqxRKEqbNybyVPfLKeqV9solvbBP561WAGd0kOX0ClhbDta9jypZMw9q5yEgYCaX2cI4suw53X1N7OBXJjzAlZgjD1tmBzPve+tpQ9xUe4+3u9+NGYHkR6GkEPLUeKYedi2LEIchZCzqJj3XxExkH7/tBxIHQYAB0GQftMiIoLb8zGNEKWIMxJKTxczq/fXcl7y3IZmN6aP10+kH4dW4U7rOOpQv5GyMmG3cth13LYvQKOFDrrxeMcWbTrB2l9Ia2385rSw57yNi2aJQjTIN5fnstD762i4FA5Pzy7O3ed04vYqEZ8KkcVCrYdSxa7l0PeWjiwjaOP1YgHUro7p6nS+kDbXk735m0ynI4I7XZb08xZgjAN5sDBMv4waw1vLs6he2oC/+/SUxnVIzXcYdVN2SHI3+DcYpu3Fvatc7oFyd8Evs9sRiVAm25OwqhKGikZTlmrzhAZE66fwLQUlZXOw6W+k1Yvc/9m2/ao1yYsQZgG9+WGPP73nRXs2H+YCwZ04H8v6Ed6m/hwh3VyKsqgYDsc2AL7N8P+Le78Fjiw1emA0Fdie2id7iSL1l2gdWdnuXU6tEqHhDSIaATXa5qDSi94y5wBqrzlznxl+fHL3nK3rGre5wO06lW91T5cfT5s1fvd+gG38wawvWr1/Larth3/HUh8V2J7uG99vXatJQgTFKXlXqbN3czTczaiCj88uwc/OrsHcdGN+LRTfVVWQvEuJ2Ec2Or0JVW4AwpzoGin81perft0TzQkdYSkDs7pqsQOkNTeffUpS0ht+nddeSvgSJEzlRY6Y5dXny8/BOWHnami1F0udeeryg+7ZYed9/SWOVOgH5QNKSIKIiKd302Ex52PdE5L+iuP8Pisq6mdb1uf1++0i/SzXEudqHjo9/16/ZiWIExQ5RYc5pEP1/KfZbl0bB3L3ef24vIh6Y3jbqdQUXXuoirMOZY0CrY7SaVkDxTvgZLdzgdmdeJxjjYS20F8W4hPgbgUP69tnNfoROfp8qi4hrlGUul1P8yLnLvDjrivpUXORf7qH/alhcfqV82XlZx4OxFRzgdZVKzzPEvVfFS8uxznTJHu+sgY58PPEw2eKGeKiHKXq8qja6jjvn7nQ7WmD+TqH+Qt52/XEoQJiYVb9vOHWWtYtqOA7qkJ3DuuNxec2pGICLvQe1T5YZ+E4U7Fu53kUbIXDu2Hw/ud19JCav/mLM6Ha3S8+5rgfouNcCef+coK5xRZRdnxr+WlzhPrJxIRBbGtIbYVxLTymW99bD62tbuu+nyyM0Stp4H79zINwhKECRlV5ZPVe/jz7HWs31NC/06tuOfc3nyvXzvE7giqm0ovHC44ljAO73eOUsoOHpvKDx3/qpXuRUzvsXn1ut+yY5xben1fo+KcD/KYJPcDP+nYB/vR8tbON3r7/TVLliBMyHkrlfeW7eSvn2xg+/5D9O2QxI/G9ODCAR1b1qknYxo5SxAmbMq9lby/PJenP9/Ehr0ldE2J5/bR3Zk4NL1xP0NhTAthCcKEXWWl8umaPUyZs4llOwpISYhm0rAuXDfyFDolWxcYxoSLJQjTaKgq8zfnM+OrrXy6Zg8iwrjM9tw4qhsjMlLsOoUxIVZbgghxH86mpRMRRvVIZVSPVHbsP8RL32zj1YU7+HDlbnq1S+TKrC5cclpn0pLsKWVjws2OIEzYHS7z8t6ynby6aAffbi8gMkIY27cdV2Z1YUyfNKLsorYxQWOnmEyTsXFvMW9k5/DWkhz2lZSRmhjNhQM6ctGgTgzp2saeqTCmgYVzyNEJwN9xhg19VlUfrbb+YuBhoBKoAO5W1Xnuuq1AMeAFKmr6AXxZgmg+yr2VzFmXx1uLc/hs3V7KKirp2DqW7w90ksWAzq3teoUxDSAsCUJEPMB64DwgB1gEXK2qq33qJAIHVVVFZCDwuqr2dddtBbJUdV+g27QE0TwVl5bz6Zo9vL9sF3M35FHuVbqmxHNeZnvO7deeYd3a2LMVxtRTuC5SDwc2qupmN4hXgYuBowlCVX07cEkgLD1ymcYuKTaKS09L59LT0ik8VM7Hq3Yza+UuXlywjenzttA6LoqxfdI4N7M9o3un0SrWunQwpiEEM0F0Bnb4LOcAI6pXEpFLgUeAdsCFPqsUmC0iCvxTVacFMVbTRLSOj+LKYV24clgXDh6p4MsN+/h0zR4+W7uXd5fmEuURhp7ShrN6pXFWr1T6d2qNx65bGFMvwTzFdAUwXlVvc5evB4ar6l011B8N/EZVz3WXO6lqroi0Az4B7lLVuX7a3Q7cDtC1a9eh27ZtC8rPYxo3b6WyZPsBPl2zh7nr97FmVxEAyfFRnNEzlbN6pnJW7zQ620N5xhwnXNcgTgceUtXx7vKvAFT1kVrabAGGVb/uICIPASWq+ufatmnXIEyVvOIjfLVxH19u2Me8jXnsKXIG++maEs/wjBSGZ6QwIiOFrinxdrHbtGjhugaxCOglIhnATmAScE21wHoCm9yL1EOAaCBfRBKACFUtdufHAb8PYqymmUlLiuGS0zpzyWmdUVU27C3hyw37WLgln/+u2cObi3MAaJcUczRZDM9oS692iXYrrTGuoCUIVa0QkTuBj3Fuc31OVVeJyGR3/VTgcuAGESkHDgNXucmiPfCO+80uEnhFVT8KVqymeRMRerdPonf7JG49M4PKSmVTXgnfbNnPwi37+WZLPu8v3wVAUkwkg7okM7hLMqd1dV7bJtpT3aZlsgflTIunquzYf5iFW/fz7fYDfLu9gHV7ivFWOv8bXVPij0sYmZ1aERNpPdGa5sH6YjKmFiJC17bxdG0bz8Sh6QAcKqtg5c4ivt1+gKU7Cli4ZT/vLcsFIMrjHJEM6NyaU92pb4ck677cNDuWIIzxIz468ujF7Cq7C0v5dvsBlu8sZOXOQj5atZtXFzl3ckdGCL3aJ3Fqp1YMSHeSRmbHVpY0TJNmp5iMqSdVJefAYVblFrJiZyErdhaxcmch+w+WAeCJEHqmJXJq59YM6NyK/p1b069jKxJj7HuZaTzsFJMxQSAidEmJp0tKPBNO7Qg4SWNXYSkr3KOMFTsL+WL9Xt5aknO0Xbe28WR2akX/Ts5RRmanVrRLirHbbU2jYwnCmAYkInRKjqNTchzj+3cAnKSxp+gIq3cVsjq3iFXuNGvF7qPtUhOj6ecmi6rEkZGaYE+Bm7CyBGFMkIkIHVrH0qF1LOf0bX+0vKi0nLW7ilmdW8iq3CJW7yriuXlbKPc6p33jojz07Zh09Cijf6fW9GmfRFy0XdcwoWHXIIxpRMoqKtm4t4TVu4rco41CVu8qori0AoAIge5pifTv1Opo4sjs2Mqe1TD1ZtcgjGkioiMjnA/9Tq1gqFN27GJ4kZs4Clm0ZT8zl+YebdehVezRZNG7QxLdUxPonpZAfLT9i5v6s78eYxq54y+GdzhafuBg2dEjjdW7nKONL9bnHX3AD6Bj61gy3GTRPTWRLinxdGwdS6fkONrER9mFcVMrSxDGNFFtEqI5o2cqZ/RMPVpWWu5la/5BNucdZHNeCZvzDrJp30FmLs09epqqSmxUBJ1ax9ExOZa0xBjaJESTEh9NSqLz2iYhmlaxUSTEeIiPjiQhxkNclMeSSgtiCcKYZiQ2ykPfDq3o26HVceWqSv7BMnYeOExuwWFyC0vJLTjMrsLD5BaUsn3/AQ4cLKfkSEUN7+wQcS6ex0dHEh/tIcojRHkiiI6MIMoTcWzZ4y5HOmWREYInQoiQ41+PzYNHhIgIOfbqOy/OcyXHra96r6oygQif9xNx5911cnTbx89HuPUi3BjErV8Vm/jMR4hPG5/2nginXtX2xN1GU2cJwpgWQERITYwhNTGGQV2Sa6x3pMJLwaFy9h8sY//BMopLyzl4xMuhci+HjlRwsOzY6+GyCsq9Spm3kvKqqUIpLq84tuxVyioqqaisxFsJlap4K5VKVSorFa8qlZXgdcubk+rJ57gEUy3h+EtGIm7SrJ6kfBOTu65NfDRTrx/a4D+DJQhjzFExkR7at/LQvlVsWLZflTSqkoi38vgEUlV23HpVKhWfxINbdmxd1fuqHktS6ttG+U796vNed1mPbvf4+aqkV6m426qKkePmK9113lq2ddx7VB6bP25bPj+rN0h3o1qCMMY0GhERQgSCdWHVOESEOwBjjDGNkyUIY4wxflmCMMYY45clCGOMMX4FNUGIyAQRWSciG0Xkfj/rLxaR5SKyVESyReTMQNsaY4wJrqAlCBHxAFOA84FM4GoRyaxW7b/AIFUdDNwCPFuHtsYYY4IomEcQw4GNqrpZVcuAV4GLfSuoaoke6042AdBA2xpjjAmuYCaIzsAOn+Uct+w4InKpiKwFPsA5igi4rdv+dvf0VHZeXl6DBG6MMSa4D8r564jkO4/7qeo7wDsiMhp4GDg30LZu+2nANAARyRORbfWMNxXYV8+2wWRx1Y3FVTcWV900x7hOqWlFMBNEDtDFZzkdyK2hLqo6V0R6iEhqXdv6vEdaPWNFRLJrGjQjnCyuurG46sbiqpuWFlcwTzEtAnqJSIaIRAOTgPd8K4hIT3G7PBSRIUA0kB9IW2OMMcEVtCMIVa0QkTuBjwEP8JyqrhKRye76qcDlwA0iUg4cBq5yL1r7bRusWI0xxnxXUDvrU9VZwKxqZVN95v8E/CnQtkE2LYTbqguLq24srrqxuOqmRcUlGqRuYo0xxjRt1tWGMcYYvyxBGGOM8avFJ4hw9vkkIl1E5HMRWSMiq0Tkp275QyKy0+2jaqmIXODT5ldurOtEZHwQY9sqIiuq+slyy1JE5BMR2eC+tgllXCLSx2efLBWRIhG5Oxz7S0SeE5G9IrLSp6zO+0dEhrr7eaOIPFl1V18Dx/W4iKx1+z17R0SS3fJuInLYZ79N9WnToHHVEludf3ch2mev+cS0VUSWuuUh2We1fDaE9m9M3aHsWuKEc4fUJqA7zi22y4DMEG6/IzDEnU8C1uP0PfUQcJ+f+plujDFAhhu7J0ixbQVSq5U9Btzvzt8P/CnUcVX73e3Gecgn5PsLGA0MAVaezP4BFgKn4zwc+iFwfhDiGgdEuvN/8omrm2+9au/ToHHVEludf3eh2GfV1v8F+E0o9xk1fzaE9G+spR9BhLXPJ1XdpapL3PliYA01dCniuhh4VVWPqOoWYCPOzxAqFwPPu/PPA5eEMa7vAZtUtbYn54MWl6rOBfb72V7A+0dEOgKtVHW+Ov/JL/i0abC4VHW2qla4iwtwHjytUTDiqim2WoR1n1Vxv21fCfy7tvdo6Lhq+WwI6d9YS08QAff5FGwi0g04DfjGLbrTPSXwnM9hZCjjVWC2iCwWkdvdsvaqugucP2CgXRjiqjKJ4/9pw72/oO77p7M7H6r4wOnv7EOf5QwR+VZEvhCRs9yyUMdVl99dqGM7C9ijqht8ykK6z6p9NoT0b6ylJ4iA+3wKahAiicBbwN2qWgQ8A/QABgO7cA5xIbTxnqGqQ3C6XL9DnL6yahLS/SjO0/X/A7zhFjWG/VWbmuII9X57AKgAXnaLdgFdVfU04F7gFRFpFeK46vq7C/Xv9GqO/yIS0n3m57Ohxqo1bP+k4mrpCaJefT41JBGJwvkDeFlV3wZQ1T2q6lXVSuBfHDstErJ4VTXXfd0LvOPGsMc9ZK06pN4b6rhc5wNLVHWPG2PY95errvsnh+NP9wQtPhG5Efg+cK17qgH3dES+O78Y57x171DGVY/fXSj3WSRwGfCaT7wh22f+PhsI8d9YS08QYe3zyT2/OR1Yo6pP+JR39Kl2KVB1d8V7wCQRiRGRDKAXzgWoho4rQUSSquZxLnKudLd/o1vtRmBmKOPycdy3unDvLx912j/uKYJiERnp/i3c4NOmwYjIBOCXwP+o6iGf8jRxBudCRLq7cW0OVVzuduv0uwtlbDg9S69V1aOnaEK1z2r6bCDUf2P1vcreXCbgApw7BDYBD4R422fiHO4tB5a60wXAi8AKt/w9oKNPmwfcWNfRAHeW1BBXd5w7IpYBq6r2C9AWZxTADe5rSijjcrcTj9OhY2ufspDvL5wEtQsox/mWdmt99g+QhfOhuAl4Crd3gwaOayPO+emqv7Gpbt3L3d/vMmAJcFGw4qoltjr/7kKxz9zyGcDkanVDss+o+bMhpH9j1tWGMcYYv1r6KSZjjDE1sARhjDHGL0sQxhhj/LIEYYwxxi9LEMYYY/yyBGGMMcYvSxDGhJGI/F5EznXn7xaR+HDHZEwVew7CmEZCRLYCWaq6rw5tPKrqDV5UpiWzIwhjqhFnUJg1IvIvd7CW2SISJyJzRCTLrZPqfqAjIjeJyLsi8h8R2SIid4rIvW6PnwtEJKWWbc0QkYki8hOgE/C5iHzurhsnIvNFZImIvOF23FY1mNNvRGQecEWw94dpuSxBGONfL2CKqvYHCnC6WKjNqcA1OJ3N/QE4pE6Pn/Nx+r+plao+idOJ2lhVHSsiqcCDwLnq9KqbjdN7aJVSVT1TVV+t249lTOAiwx2AMY3UFlVd6s4vxhlJrDafqzOwS7GIFAL/cctXAAPrsf2ROKOEfeX0sUY0TrKp8pq/RsY0JEsQxvh3xGfeC8ThjKVQddQdW0v9Sp/lSur3fybAJ6p6dQ3rD9bjPY2pEzvFZEzgtgJD3fmJQXj/Ypzxh8EZGvQMEekJICLxItI7CNs0pkaWIIwJ3J+BH4nI10BqEN5/GvChiHyuqnnATcC/RWQ5TsLoG4RtGlMju83VGGOMX3YEYYwxxi+7SG1MCIjIFOCMasV/V9X/C0c8xgTCTjEZY4zxy04xGWOM8csShDHGGL8sQRhjjPHLEoQxxhi//j+376cfEQk8/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses_train, label=\"loss_train\")\n",
    "plt.plot(losses_test,  label=\"loss_test\")\n",
    "plt.xlabel('num_iter')\n",
    "plt.ylabel('Log loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73827174-4ce2-4e79-9e65-d06f4080da0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
